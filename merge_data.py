#!/usr/bin/env python3
"""
RedLens æ•°æ®å·¥å‚ - æ™ºèƒ½èåˆæ¨¡å— (Smart Merge)
ä¿®å¤: 
1. å¢åŠ  +/- 1 å¤©çš„æ—¥æœŸå®¹é”™ï¼Œè§£å†³æ—¶å·®å¯¼è‡´çš„ä¸åŒ¹é…
2. å¢å¼ºæ—¥å¿—è¾“å‡ºï¼Œæ˜¾ç¤ºåŒ¹é…å¤±è´¥çš„å…·ä½“åŸå› 
"""

import json
import logging
from typing import List, Dict
from datetime import datetime, timedelta

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# æ–‡ä»¶è·¯å¾„
OFFICIAL_FILE = "matches.json"
MIGU_FILE = "migu_videos_complete.json"
OUTPUT_FILE = "matches_with_videos.json"
MAPPING_FILE = "team_name_mapping.json"

def get_fuzzy_dates(date_str: str) -> List[str]:
    """ç”Ÿæˆ [æ˜¨å¤©, ä»Šå¤©, æ˜å¤©] çš„æ—¥æœŸåˆ—è¡¨"""
    try:
        target_date = datetime.strptime(date_str, '%Y-%m-%d')
        return [
            (target_date - timedelta(days=1)).strftime('%Y-%m-%d'),
            date_str,
            (target_date + timedelta(days=1)).strftime('%Y-%m-%d')
        ]
    except:
        return [date_str]

def merge_data() -> List[Dict]:
    logger.info("ğŸ”„ å¼€å§‹æ™ºèƒ½èåˆ (Smart Merge)...")
    
    with open(OFFICIAL_FILE, 'r', encoding='utf-8') as f:
        official_matches = json.load(f)
    
    with open(MIGU_FILE, 'r', encoding='utf-8') as f:
        migu_matches = json.load(f)
    
    with open(MAPPING_FILE, 'r', encoding='utf-8') as f:
        team_mapping = json.load(f)
    
    # å»ºç«‹å’ªå’•ç´¢å¼•
    migu_index = {}
    for m in migu_matches:
        d = m['date']
        if d not in migu_index: migu_index[d] = []
        migu_index[d].append(m)
    
    merged_matches = []
    match_count = 0
    
    for official in official_matches:
        merged = official.copy()
        date = official['date']
        opponent = official['opponent']
        opponent_cn = team_mapping.get(opponent, opponent) # ç¿»è¯‘
        
        found = False
        
        # æ ¸å¿ƒä¿®å¤: å°è¯• æ˜¨å¤©/ä»Šå¤©/æ˜å¤©
        candidate_dates = get_fuzzy_dates(date)
        
        for check_date in candidate_dates:
            if check_date in migu_index:
                for migu in migu_index[check_date]:
                    migu_opp = migu['opponent']
                    
                    # æ¨¡ç³ŠåŒ¹é…é˜Ÿå
                    if (opponent_cn in migu_opp or migu_opp in opponent_cn or 
                        opponent.lower() in migu_opp.lower()):
                        
                        merged['migu_pid'] = migu.get('pid', '')
                        merged['migu_detail_url'] = migu.get('detail_url', '')
                        merged['migu_live_url'] = migu.get('live_url', '')
                        
                        match_count += 1
                        found = True
                        
                        # å¦‚æœæ—¥æœŸä¸ä¸€è‡´ï¼Œè®°å½•ä¸€ä¸‹
                        if check_date != date:
                            logger.info(f"âœ… æ¨¡ç³ŠåŒ¹é…æˆåŠŸ: {date} -> {check_date} | {opponent_cn}")
                        else:
                            logger.info(f"âœ… ç²¾å‡†åŒ¹é…: {date} vs {opponent_cn}")
                        break
            if found: break
        
        if not found:
            # åˆå§‹åŒ–ä¸ºç©º
            merged['migu_pid'] = ''
            merged['migu_detail_url'] = ''
            merged['migu_live_url'] = ''
            
            # è°ƒè¯•æ—¥å¿—ï¼šä¸ºä»€ä¹ˆæ²¡åŒ¹é…ä¸Šï¼Ÿ
            # logger.debug(f"âŒ æœªåŒ¹é…: {date} {opponent} (å¯èƒ½åŸå› : å’ªå’•æ— æ•°æ® æˆ– é˜Ÿåæœªæ˜ å°„)")
        
        merged_matches.append(merged)
    
    logger.info(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: æˆåŠŸåŒ¹é… {match_count} / {len(merged_matches)} åœº")
    return merged_matches

def save_merged_data(matches):
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(matches, f, ensure_ascii=False, indent=2)
    logger.info(f"ğŸ’¾ å·²ä¿å­˜è‡³ {OUTPUT_FILE}")

if __name__ == "__main__":
    data = merge_data()
    save_merged_data(data)